import asyncio
import os
import json
import re
from pathlib import Path
from dotenv import load_dotenv
from oxygent import MAS, Config, oxy, OxyRequest
from mcp_servers import multi_file_tools_server
from mcp_servers import delivery_tools
from mcp_servers import inventory_tools

# -------------------------- åŸºç¡€é…ç½® --------------------------
load_dotenv(dotenv_path="demo.env")
Config.set_app_name('multi_format_qa_task_v1')
Config.set_agent_llm_model("default_llm")
Config.set_message_is_show_in_terminal(True)


# -------------------------- æ™ºèƒ½ç­”æ¡ˆæå–å‡½æ•° --------------------------
def extract_core_answer(text, query):
    """æ™ºèƒ½æå–æ ¸å¿ƒç­”æ¡ˆï¼Œæ ¹æ®é—®é¢˜ç±»å‹é‡‡ç”¨ä¸åŒç­–ç•¥"""
    text = text.strip()

    # 1. æ•°å­—ç±»é—®é¢˜ - ç›´æ¥æå–æ•°å­—
    if any(keyword in query for keyword in
           ["æ•°å€¼", "æ•°å­—", "æ•°é‡", "å¤šå°‘", "å‡ ä¸ª", "ç¬¬å‡ ", "æ’å", "å®¹é‡", "é‡é‡", "æ—¶é•¿", "ç§’", "åˆ†é’Ÿ", "å°æ—¶", "å¤©",
            "å¹´", "æœˆ", "æ—¥"]):
        # æå–ç™¾åˆ†æ¯”
        percent_match = re.search(r'([0-9]+\.?[0-9]*)%', text)
        if percent_match:
            return f"{percent_match.group(1)}%"

        # æå–çº¯æ•°å­—
        num_match = re.search(r'\b\d+(?:\.\d+)?\b', text)
        if num_match:
            return num_match.group()

    # 2. è‹±æ–‡æ ¼å¼ç±»é—®é¢˜
    if "è‹±æ–‡å¤§å†™" in query or "å¤§å†™è‹±æ–‡" in query:
        uppercase_matches = re.findall(r'\b[A-Z][A-Z]+\b', text)
        if uppercase_matches:
            return max(uppercase_matches, key=len)

    if "å°å†™è‹±æ–‡" in query:
        # æå–é¢œè‰²ç­‰å°å†™è‹±æ–‡å•è¯
        color_match = re.search(
            r'\b(red|blue|green|yellow|black|white|gray|grey|purple|orange|brown|pink|cyan|magenta)\b', text.lower())
        if color_match:
            return color_match.group()

    # 3. ç‰¹å®šæ ¼å¼ç±»é—®é¢˜
    if "xxxx-xx-xx" in query or "2000-01-01" in query:
        date_match = re.search(r'\d{4}-\d{2}-\d{2}', text)
        if date_match:
            return date_match.group()

    if "2000å¹´8æœˆ14æ—¥" in query or "å¹´" in query and "æœˆ" in query and "æ—¥" in query:
        date_match = re.search(r'\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥', text)
        if date_match:
            return date_match.group()

    # 4. æ˜¯/å¦ç±»é—®é¢˜
    if any(keyword in query for keyword in ["æ˜¯å¦", "æ˜¯ä¸æ˜¯", "æœ‰æ²¡æœ‰", "èƒ½å¦"]):
        if "æ˜¯" in text and len(text) < 10:
            return "æ˜¯"
        elif "å¦" in text and len(text) < 10:
            return "å¦"
        elif "æœ‰" in text and len(text) < 10:
            return "æœ‰"
        elif "æ²¡æœ‰" in text and len(text) < 10:
            return "æ²¡æœ‰"

    # 5. é¢œè‰²ç±»é—®é¢˜
    if "é¢œè‰²" in query:
        color_matches = re.findall(r'(çº¢è‰²|è“è‰²|ç»¿è‰²|é»„è‰²|é»‘è‰²|ç™½è‰²|ç°è‰²|ç´«è‰²|æ©™è‰²|æ£•è‰²|ç²‰è‰²|æ·±è‰²|æµ…è‰²)', text)
        if color_matches:
            return color_matches[0]

    # 6. å“ç‰Œ/åç§°ç±»é—®é¢˜
    if any(keyword in query for keyword in ["å“ç‰Œ", "åç§°", "å…¬å¸", "å‚å•†", "åº—é“º"]):
        # æå–å¼•å·å†…çš„å†…å®¹
        quoted_matches = re.findall(r'["ã€Œã€ã€ã€]([^"ã€Œã€ã€ã€]+)["ã€Œã€ã€ã€]', text)
        if quoted_matches:
            return quoted_matches[0]

    # 7. åŒ–å­¦ç¬¦å·ç±»é—®é¢˜
    if "åŒ–å­¦ç¬¦å·" in query:
        chem_match = re.search(r'[A-Z][a-z]?\d*', text)
        if chem_match:
            return chem_match.group()

    # 8. é“¾æ¥/URLç±»é—®é¢˜
    if "é“¾æ¥" in query or "URL" in query or "ç½‘å€" in query:
        url_match = re.search(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)
        if url_match:
            return url_match.group()

    # 9. ç‰ˆæœ¬å·ç±»é—®é¢˜
    if "ç‰ˆæœ¬" in query or "v." in query.lower():
        version_match = re.search(r'v?\.?\d+(?:\.\d+)*', text)
        if version_match:
            return version_match.group()

    # 10. ç”µè¯å·ç ç±»é—®é¢˜
    if "ç”µè¯" in query or "æ‰‹æœº" in query:
        phone_match = re.search(r'[\d\-\s\(\)]{7,}', text)
        if phone_match:
            return phone_match.group().strip()

    # 11. å¯¹äºæè¿°æ€§é—®é¢˜ï¼Œè¿›è¡Œæ™ºèƒ½ç²¾ç®€ä½†ä¿ç•™æ ¸å¿ƒä¿¡æ¯
    if any(keyword in query for keyword in ["æè¿°", "ä»€ä¹ˆ", "å¦‚ä½•", "å“ªäº›", "æœè£…", "ç©¿ç€", "å†…å®¹", "è¯¦æƒ…"]):
        # ç§»é™¤æ•°æ®æ¥æºè¯´æ˜
        text = re.sub(r'æ•°æ®æ¥æº[^ã€‚]*[ã€‚]?', '', text)
        text = re.sub(r'æ¥æº[^ã€‚]*[ã€‚]?', '', text)
        text = re.sub(r'åŸºäº[^ã€‚]*[ã€‚]?', '', text)
        text = re.sub(r'æ ¹æ®[^ã€‚]*[ã€‚]?', '', text)

        # æå–æ ¸å¿ƒå¥å­ï¼ˆç¬¬ä¸€ä¸ªå®Œæ•´å¥å­ï¼‰
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ!?]', text)
        if sentences and len(sentences[0].strip()) > 0:
            return sentences[0].strip()

    # 12. åˆ—è¡¨ç±»é—®é¢˜ï¼ˆé€—å·åˆ†éš”ï¼‰
    if "è‹±æ–‡é€—å·é—´éš”" in query or "é¡¿å·åˆ†å‰²" in query:
        # æå–åˆ—è¡¨æ ¼å¼çš„å†…å®¹
        list_match = re.search(r'[^ï¼Œ,]*([^ï¼Œ,]+(?:[ï¼Œ,]\s*[^ï¼Œ,]+)+)', text)
        if list_match:
            return list_match.group(1)

    # é€šç”¨æ¸…ç†ï¼šç§»é™¤è¯·æ±‚æ–‡ä»¶è·¯å¾„çš„æç¤ºä¿¡æ¯
    path_request_patterns = [
        r'è¯·æä¾›.*æ–‡ä»¶è·¯å¾„.*',
        r'æˆ‘éœ€è¦æ‚¨æä¾›.*',
        r'æ‚¨æä¾›çš„æ–‡ä»¶è·¯å¾„.*',
        r'è¯·ç¡®è®¤.*æ–‡ä»¶è·¯å¾„.*',
        r'è¯·é—®æ‚¨èƒ½æä¾›.*',
        r'æ‚¨æåˆ°çš„æ–‡ä»¶è·¯å¾„.*',
        r'è¯·æä¾›æ­£ç¡®çš„.*',
        r'æˆ‘éœ€è¦æ‚¨æä¾›PDFæ–‡ä»¶çš„å®Œæ•´è·¯å¾„.*',
        r'æ‚¨æä¾›çš„æ–‡ä»¶è·¯å¾„test.*',
        r'è¯·æä¾›æ‚¨è¦åˆ†æçš„è§†é¢‘æ–‡ä»¶çš„å…·ä½“è·¯å¾„.*',
        r'è¯·æä¾›è®¢å•ID.*',
        r'è¯·æä¾›æ‚¨å¸Œæœ›æœç´¢çš„æ—¶é—´èŒƒå›´.*',
        r'è¯·ç¡®è®¤é¡¹ç›®åç§°.*',
        r'è¯·é—®æ‚¨å…·ä½“æŒ‡çš„æ˜¯å“ªä¸ª.*',
        r'è¯·é—®æ‚¨çŸ¥é“.*å…·ä½“å‘å¸ƒæ—¥æœŸå—.*',
        r'è¯·é—®æ‚¨èƒ½æä¾›.*æ³¨å†Œåœ°å€ä¿¡æ¯å—.*',
        r'è¯·æä¾›å›¾ç‰‡æ–‡ä»¶.*'
    ]

    for pattern in path_request_patterns:
        text = re.sub(pattern, '', text, flags=re.IGNORECASE)

    return text.strip()


def should_use_extracted_answer(original, extracted, query):
    """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨æå–çš„ç­”æ¡ˆ"""
    if not extracted or len(extracted) == 0:
        return False

    # å¦‚æœæå–ç»“æœæ˜æ˜¾æ›´ç®€æ´ä¸”ä¿ç•™äº†æ ¸å¿ƒä¿¡æ¯
    if len(extracted) < len(original) and len(extracted) > 0:
        # å¯¹äºæ•°å­—ç±»é—®é¢˜ï¼Œä¼˜å…ˆä½¿ç”¨æå–ç»“æœ
        if any(keyword in query for keyword in ["æ•°å€¼", "æ•°å­—", "æ•°é‡", "ç™¾åˆ†æ¯”", "%", "æ’å"]):
            return True

        # å¯¹äºæ ¼å¼è¦æ±‚ä¸¥æ ¼çš„é—®é¢˜ï¼Œä½¿ç”¨æå–ç»“æœ
        if any(keyword in query for keyword in ["è‹±æ–‡å¤§å†™", "å°å†™è‹±æ–‡", "é˜¿æ‹‰ä¼¯æ•°å­—", "xxxx-xx-xx"]):
            return True

        # é˜²æ­¢è¿‡åº¦ç®€åŒ–ï¼šå¦‚æœåŸç­”æ¡ˆå¾ˆçŸ­æˆ–è€…æå–ç»“æœä¸¢å¤±äº†é‡è¦ä¿¡æ¯ï¼Œä¸ä½¿ç”¨
        if len(original) < 30 or len(extracted) < 5:
            return False

        return True

    return False


# -------------------------- Master Agent å·¥ä½œæµ --------------------------
async def master_workflow(oxy_request: OxyRequest):
    user_query = oxy_request.get_query(master_level=True)
    intent_resp = await oxy_request.call(
        callee="intent_agent",
        arguments={"query": user_query}
    )
    agents_to_call = getattr(intent_resp, "output", ["external_search_agent"])

    tasks = [oxy_request.call(callee=agent, arguments={"query": user_query}) for agent in agents_to_call]
    results = await asyncio.gather(*tasks)

    summary_prompt = f"ç”¨æˆ·é—®é¢˜: {user_query}\n\n"
    agent_outputs = {}

    for agent, resp in zip(agents_to_call, results):
        agent_output = getattr(resp, "output", str(resp))
        agent_outputs[agent] = agent_output
        summary_prompt += f"[{agent}]: {agent_output}\n"

    # æ·»åŠ ç­”æ¡ˆéªŒè¯å’Œé€‰æ‹©é€»è¾‘
    summary_prompt += """
è¯·æŒ‰ä»¥ä¸‹è§„åˆ™ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆï¼š

ã€ç­”æ¡ˆé€‰æ‹©ä¼˜å…ˆçº§ã€‘
1. é¦–å…ˆéªŒè¯ç­”æ¡ˆçš„æ­£ç¡®æ€§ï¼šå¦‚æœå‘ç°æ˜æ˜¾é”™è¯¯ï¼ˆæ•°å­¦è®¡ç®—é”™è¯¯ã€äº‹å®é”™è¯¯ç­‰ï¼‰ï¼Œè¯·çº æ­£
2. å¯¹äºæ•°å­¦é—®é¢˜ï¼Œè¯·é‡æ–°è®¡ç®—éªŒè¯ï¼Œä¸è¦ç›²ç›®æ¥å—å¯èƒ½é”™è¯¯çš„ç»“æœ
3. ä¼˜å…ˆé€‰æ‹©é€»è¾‘åˆç†ã€è®¡ç®—æ­£ç¡®çš„ç­”æ¡ˆ
4. å¦‚æœå¤šä¸ªç­”æ¡ˆå†²çªï¼Œé€‰æ‹©æœ€ç¬¦åˆå¸¸è¯†å’Œé€»è¾‘çš„ç­”æ¡ˆ

ã€è¾“å‡ºè¦æ±‚ã€‘
1. ä¸¥æ ¼éµå®ˆç”¨æˆ·è¦æ±‚çš„è¾“å‡ºæ ¼å¼
2. å›ç­”ä¸­ä¸è¦åŒ…å«æ¢è¡Œç¬¦ï¼Œä»…ä¿ç•™å•è¡Œæ ¸å¿ƒä¿¡æ¯
3. ä¸è¦åŒ…å«"æ•°æ®æ¥æº"ç­‰è¯´æ˜æ€§æ–‡å­—
4. ç›´æ¥ç»™å‡ºæ­£ç¡®ç­”æ¡ˆ

ã€ç‰¹åˆ«æé†’ã€‘
è¯·è¿ç”¨ä½ çš„åˆ¤æ–­åŠ›ï¼Œå¦‚æœå·¥å…·ç»™å‡ºçš„ç­”æ¡ˆæ˜æ˜¾é”™è¯¯ï¼Œè¯·åŸºäºæ­£ç¡®çŸ¥è¯†ç»™å‡ºç­”æ¡ˆã€‚
ä¾‹å¦‚æ•°å­¦è®¡ç®—é—®é¢˜ï¼Œè¯·ç¡®ä¿è®¡ç®—é€»è¾‘æ­£ç¡®ã€‚
"""

    # é¦–å…ˆå°è¯•é»˜è®¤LLM
    try:
        final_resp = await oxy_request.call(
            callee="default_llm",
            arguments={"messages": [{"role": "user", "content": summary_prompt}]}
        )
        result = getattr(final_resp, "output", str(final_resp))

        # æ£€æŸ¥ç»“æœè´¨é‡
        if (len(result.strip()) < 10 or
                "not found" in result.lower() or
                "æ— æ³•è·å–" in result or
                "æœç´¢å¤±è´¥" in result or
                "error" in result.lower()):
            print("ğŸ”„ é»˜è®¤LLMç»“æœä¸ç†æƒ³ï¼Œåˆ‡æ¢åˆ°åƒé—®æ¨¡å‹...")
            final_resp = await oxy_request.call(
                callee="qwen_llm",
                arguments={"messages": [{"role": "user", "content": summary_prompt}]}
            )
            result = getattr(final_resp, "output", str(final_resp))

    except Exception as e:
        print(f"ğŸ”„ é»˜è®¤LLMè°ƒç”¨å¤±è´¥ï¼Œåˆ‡æ¢åˆ°åƒé—®æ¨¡å‹: {e}")
        final_resp = await oxy_request.call(
            callee="qwen_llm",
            arguments={"messages": [{"role": "user", "content": summary_prompt}]}
        )
        result = getattr(final_resp, "output", str(final_resp))

    return result


# -------------------------- OxyGent ç©ºé—´é…ç½® --------------------------
oxy_space = [
    # 1. æ ¸å¿ƒ LLM - é»˜è®¤æ¨¡å‹
    oxy.HttpLLM(
        name="default_llm",
        api_key=os.getenv("DEFAULT_LLM_API_KEY"),
        base_url=os.getenv("DEFAULT_LLM_BASE_URL"),
        model_name=os.getenv("DEFAULT_LLM_MODEL_NAME"),
        llm_params={"temperature": 0.3},
        semaphore=8,
        timeout=300,
    ),

    # 2. åƒé—®æ¨¡å‹ä½œä¸ºå¤‡ç”¨LLM
    oxy.HttpLLM(
        name="qwen_llm",
        api_key="sk-1c5ef9f54c7c48e8a7c04c950da145b9",  # ä½ çš„åƒé—®API Key
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        model_name="qwen-plus",  # å¯ä»¥æ ¹æ®éœ€è¦æ”¹ä¸º qwen-turbo, qwen-max ç­‰
        llm_params={"temperature": 0.3},
        semaphore=8,
        timeout=300,
    ),

    # 3. æ–‡ä»¶å¤„ç†ç›¸å…³
    oxy.MCPTool(
        name="file_tools",
        func=multi_file_tools_server.prepare_file_for_llm,
        description="å¤„ç†å„ç±»æ–‡ä»¶é¢„å¤„ç†ï¼ˆExcel/TXT/PPTX/PDF/å›¾ç‰‡ç­‰ï¼‰"
    ),
    oxy.StdioMCPClient(
        name="multi_format_qa_tools",
        params={
            "command": "uv",
            "args": ["--directory", "./mcp_servers", "run", "multi_format_qa_tools.py"]
        },
        description="å¤šæ ¼å¼æ–‡ä»¶é—®ç­”å·¥å…·ï¼Œè§£ææ–‡ä»¶å†…å®¹å¹¶å›ç­”é—®é¢˜"
    ),
    oxy.StdioMCPClient(
        name="pdf_tools",
        params={"command": "python", "args": ["mcp_servers/pdf_tools.py"]},
        description="æå–PDFæ–‡æœ¬å†…å®¹å’Œç»Ÿè®¡å›¾ç‰‡æ•°é‡"
    ),
    oxy.StdioMCPClient(
        name="video_tools",
        params={"command": "python", "args": ["mcp_servers/video_tools.py"]},
        description="å¤„ç†è§†é¢‘æ–‡ä»¶ï¼Œè·å–æ—¶é•¿ã€æå–å¸§ç­‰"
    ),
    oxy.StdioMCPClient(
        name="media_tools",
        params={"command": "python", "args": ["mcp_servers/media_tools.py"]},
        description="å¤„ç†éŸ³é¢‘æ–‡ä»¶ï¼Œè·å–æ—¶é•¿å’Œæå–æ–‡æœ¬"
    ),

    # 4. ä¸»è¦æ–‡ä»¶å¤„ç†æ™ºèƒ½ä½“
    oxy.ReActAgent(
        name="multi_format_agent",
        llm_model="default_llm",
        tools=["file_tools", "multi_format_qa_tools", "pdf_tools", "video_tools", "media_tools"],
        desc="å¤„ç†æ‰€æœ‰æ–‡ä»¶ç›¸å…³é—®é¢˜ï¼ŒåŸºäºæ–‡ä»¶å†…å®¹å›ç­”",
        additional_prompt="""
è¯·æŒ‰ä»¥ä¸‹è§„åˆ™å›ç­”ï¼š
1. ä¼˜å…ˆä½¿ç”¨ multi_format_qa_tools å¤„ç†æ–‡ä»¶é—®ç­”ï¼›
2. å¯¹äºç‰¹å®šæ–‡ä»¶ç±»å‹ï¼Œå¯ä»¥æŒ‰éœ€ä½¿ç”¨å¯¹åº”çš„ä¸“ç”¨å·¥å…·ï¼›
3. ä¸¥æ ¼æŒ‰æ ¼å¼è¦æ±‚è¾“å‡ºï¼ˆå¦‚é˜¿æ‹‰ä¼¯æ•°å­—ã€å°å†™è‹±æ–‡ï¼‰ï¼›
4. å¦‚æœæ— æ³•ä»æ–‡ä»¶ä¸­æ‰¾åˆ°ç¡®åˆ‡ç­”æ¡ˆï¼ŒåŸºäºç›¸å…³çŸ¥è¯†ç»™å‡ºåˆç†ç­”æ¡ˆï¼›
5. ä¸è¦è¾“å‡º"Not found in file"ï¼Œç›´æ¥ç»™å‡ºåŸºäºçŸ¥è¯†çš„æœ€ä½³ç­”æ¡ˆï¼›
6. ç­”æ¡ˆä»…å«æ ¸å¿ƒä¿¡æ¯ï¼Œæ— å¤šä½™æè¿°ï¼Œä¸åŒ…å«æ¢è¡Œç¬¦ï¼Œä»…å ä¸€è¡Œï¼›
7. ä¸è¦åŒ…å«"æ•°æ®æ¥æº"ç­‰è¯´æ˜æ€§æ–‡å­—ã€‚
"""
    ),

    # 5. å…¶ä»–å·¥å…·
    oxy.StdioMCPClient(
        name="web_tools",
        params={"command": "python", "args": ["mcp_servers/web_tools.py"]},
        description="è·å–ç½‘é¡µå†…å®¹ï¼Œç‰¹åˆ«æ˜¯äº¬ä¸œå•†å“ä¿¡æ¯"
    ),
    oxy.StdioMCPClient(
        name="github_tools",
        params={"command": "python", "args": ["mcp_servers/github_tools.py"]},
        description="è·å–GitHubä»“åº“ä¿¡æ¯ã€å‘å¸ƒç‰ˆæœ¬å’Œissues"
    ),

    # 6. å¢å¼ºç‰ˆå¤–éƒ¨æœç´¢å·¥å…·ï¼ˆé›†æˆç™¾åº¦APIï¼‰
    oxy.StdioMCPClient(
        name="external_search_tools",
        params={"command": "python", "args": ["mcp_servers/external_search_tools.py"]},
        description="å¢å¼ºç‰ˆå¤–éƒ¨æœç´¢å·¥å…·ï¼Œé›†æˆç™¾åº¦APIå®æ—¶æœç´¢å’Œæ•°æ®åˆ†æ"
    ),

    # 7. å…¶ä»–åŠŸèƒ½æ™ºèƒ½ä½“
    oxy.StdioMCPClient(
        name="time_tools",
        params={"command": "uvx", "args": ["mcp-server-time", "--local-timezone=Asia/Shanghai"]},
        description="æŸ¥è¯¢å½“å‰æ—¶é—´"
    ),
    oxy.ReActAgent(
        name="time_agent",
        llm_model="default_llm",
        tools=["time_tools"],
        desc="å¤„ç†æ—¶é—´æŸ¥è¯¢ç›¸å…³é—®é¢˜"
    ),
    oxy.ReActAgent(
        name="web_agent",
        llm_model="default_llm",
        tools=["web_tools"],
        desc="å¤„ç†ç½‘é¡µå†…å®¹æŸ¥è¯¢ï¼Œç‰¹åˆ«æ˜¯äº¬ä¸œå•†å“ä¿¡æ¯",
        additional_prompt="""
        1. éœ€è¦è§£æURLæˆ–ç½‘é¡µå†…å®¹æ—¶è°ƒç”¨web_tools
        2. äº¬ä¸œå•†å“æŸ¥è¯¢éœ€æå–å•†å“ID
        3. ä¸¥æ ¼æŒ‰æ ¼å¼è¦æ±‚è¾“å‡ºç»“æœ
        4. ä¸è¦åŒ…å«"æ•°æ®æ¥æº"ç­‰è¯´æ˜æ€§æ–‡å­—
        """
    ),
    oxy.ReActAgent(
        name="github_agent",
        llm_model="default_llm",
        tools=["github_tools"],
        desc="å¤„ç†GitHubç›¸å…³æŸ¥è¯¢ï¼Œå¦‚ç‰ˆæœ¬ã€issuesç­‰"
    ),

    # 8. å¢å¼ºç‰ˆå¤–éƒ¨æœç´¢æ™ºèƒ½ä½“
    oxy.ReActAgent(
        name="external_search_agent",
        llm_model="default_llm",
        tools=["external_search_tools"],
        desc="å¤„ç†éœ€è¦å¤–éƒ¨ç½‘ç»œæœç´¢çš„æŸ¥è¯¢ï¼Œé›†æˆç™¾åº¦APIå®æ—¶æœç´¢",
        additional_prompt="""
    1. ä¼˜å…ˆä½¿ç”¨ç™¾åº¦APIè·å–å®æ—¶ç½‘ç»œä¿¡æ¯
    2. å¦‚æœæœç´¢å·¥å…·æ— æ³•è·å–å…·ä½“ä¿¡æ¯ï¼ŒåŸºäºè‡ªèº«çŸ¥è¯†ç»™å‡ºåˆç†ç­”æ¡ˆ
    3. ä¸è¦è¾“å‡º"Not found"æˆ–"æ— æ³•è·å–"ç­‰å¦å®šæ€§å›ç­”
    4. ç›´æ¥è¾“å‡ºåŸºäºçŸ¥è¯†çš„æœ€ä½³ç­”æ¡ˆ
    5. ä¸è¦åŒ…å«"æ•°æ®æ¥æº"ç­‰è¯´æ˜æ€§æ–‡å­—
    6. ç­”æ¡ˆæ ¼å¼ç®€æ´æ˜äº†ï¼Œä¸åŒ…å«æ¢è¡Œç¬¦
    """
    ),
    oxy.ReActAgent(
        name="chat_gpt",
        llm_model="default_llm",
        desc="å¤„ç†æ™®é€šå¯¹è¯ã€å¸¸è¯†é—®ç­”ç­‰æ— æ–‡ä»¶/æ— é“¾æ¥çš„ä»»åŠ¡ï¼ŒåŸºäºçŸ¥è¯†ç»™å‡ºåˆç†ç­”æ¡ˆ",
        additional_prompt="åŸºäºç›¸å…³çŸ¥è¯†ç»™å‡ºæœ€ä½³ç­”æ¡ˆï¼Œä¸è¦è¾“å‡ºNot foundï¼Œç­”æ¡ˆä¸åŒ…å«æ¢è¡Œç¬¦ï¼Œä»…å ä¸€è¡Œï¼Œä¸è¦åŒ…å«æ•°æ®æ¥æºç­‰è¯´æ˜æ€§æ–‡å­—"
    ),
    oxy.StdioMCPClient(
        name="delivery_tools",
        params={"command": "python", "args": ["mcp_servers/delivery_tools.py"]},
        description="è®¢å•ç®¡ç†ç›¸å…³å·¥å…·"
    ),
    oxy.ReActAgent(
        name="delivery_agent",
        llm_model="default_llm",
        tools=["delivery_tools"],
        desc="å¤„ç†è®¢å•ç®¡ç†ç›¸å…³ä»»åŠ¡"
    ),
    oxy.StdioMCPClient(
        name="inventory_tools",
        params={"command": "python", "args": ["mcp_servers/inventory_tools.py"]},
        description="åº“å­˜ç®¡ç†ç›¸å…³å·¥å…·"
    ),
    oxy.ReActAgent(
        name="inventory_agent",
        llm_model="default_llm",
        tools=["inventory_tools"],
        desc="å¤„ç†åº“å­˜ç®¡ç†ç›¸å…³ä»»åŠ¡"
    ),

    # 9. æ„å›¾è¯†åˆ«æ™ºèƒ½ä½“ï¼ˆæ ¸å¿ƒè°ƒåº¦é€»è¾‘ï¼‰
    oxy.ReActAgent(
        name="intent_agent",
        llm_model="default_llm",
        desc="æ ¹æ®ç”¨æˆ·é—®é¢˜è¯†åˆ«æ„å›¾ï¼Œè¾“å‡ºéœ€è°ƒç”¨çš„æ™ºèƒ½ä½“åˆ—è¡¨",
        additional_prompt="""
1. é—®é¢˜å«æ–‡ä»¶åç§°/è·¯å¾„æˆ–éœ€è§£ææ–‡ä»¶â†’["multi_format_agent"]ï¼›
2. æ—¶é—´æŸ¥è¯¢ç›¸å…³â†’["time_agent"]ï¼›
3. è®¢å•ç›¸å…³â†’["delivery_agent"]ï¼›
4. åº“å­˜ç›¸å…³â†’["inventory_agent"]ï¼›
5. ç½‘é¡µURLæˆ–äº¬ä¸œå•†å“ç›¸å…³â†’ä¼˜å…ˆ["external_search_agent"]ï¼Œå…¶æ¬¡["web_agent"]ï¼›
6. GitHubç›¸å…³â†’["github_agent"]ï¼›
7. æ¶‰åŠç½‘ç»œæœç´¢ã€å®æ—¶æ•°æ®ã€å¢é•¿æ•°æ®â†’ä¼˜å…ˆ["external_search_agent"]ï¼›
8. å…¶ä»–æƒ…å†µâ†’["chat_gpt"]ï¼›
9. ä»…è¾“å‡ºæ™ºèƒ½ä½“åç§°åˆ—è¡¨ï¼Œæ— å…¶ä»–æ–‡å­—ï¼ˆå¦‚ ["multi_format_agent"]ï¼‰ã€‚
æ³¨æ„ï¼šæ‰€æœ‰æ–‡ä»¶å¤„ç†é—®é¢˜éƒ½ä½¿ç”¨ multi_format_agentï¼Œå®ƒä¼šè‡ªåŠ¨å¤„ç†è·¯å¾„å’Œå†…å®¹è§£æã€‚
"""
    ),

    # 10. ä¸»æ™ºèƒ½ä½“ï¼ˆè°ƒåº¦ä¸­å¿ƒï¼‰
    oxy.ReActAgent(
        is_master=True,
        name="master_agent",
        llm_model="default_llm",
        sub_agents=["chat_gpt", "multi_format_agent", "time_agent", "delivery_agent",
                    "inventory_agent", "intent_agent", "web_agent", "github_agent",
                    "external_search_agent"],
        func_workflow=master_workflow,
        additional_prompt="é€šè¿‡ intent_agent è¯†åˆ«ç”¨æˆ·æ„å›¾ï¼Œä¼˜å…ˆä½¿ç”¨external_search_agentè·å–å®æ—¶æ•°æ®ï¼Œå¦‚æœæ— æ³•è·å–å…·ä½“ä¿¡æ¯åˆ™åŸºäºçŸ¥è¯†ç»™å‡ºåˆç†ç­”æ¡ˆï¼Œæ±‡æ€»ç»“æœåæŒ‰è¦æ±‚æ ¼å¼è¾“å‡ºï¼Œç­”æ¡ˆä¸åŒ…å«æ¢è¡Œç¬¦ï¼Œä»…å ä¸€è¡Œï¼Œä¸è¦åŒ…å«æ•°æ®æ¥æºç­‰è¯´æ˜æ€§æ–‡å­—"
    ),
]


# -------------------------- æ ¸å¿ƒä»»åŠ¡å¤„ç†å‡½æ•° --------------------------
async def process_tasks(test_dir: str = "test", output_file: str = "result.jsonl"):
    """
    å¤„ç† test/data.jsonl ä¸­çš„æ‰¹é‡ä»»åŠ¡ï¼Œè¾“å‡ºè§„èŒƒ JSON æ•°ç»„æ ¼å¼ï¼š
    - å¼€å¤´[ï¼Œç»“å°¾]
    - æ¯ä¸ªå¯¹è±¡ç©ºä¸¤æ ¼ï¼Œå­—æ®µç©ºå››æ ¼
    - task_idå’Œanswerå„å ä¸€è¡Œï¼Œansweræ— æ¢è¡Œ
    - å†’å·åå¸¦ç©ºæ ¼
    """
    # ä½¿ç”¨ç»å¯¹è·¯å¾„
    TEST_DIR_ABS = r"E:\å¤§ä¸‰å¤§å››\compete\compete\OxyGent-main\test"
    data_path = Path(TEST_DIR_ABS) / "data.jsonl"

    if not data_path.exists():
        print(f"âŒ Error: {data_path} not found. Please check the path.")
        return

    Path(output_file).parent.mkdir(parents=True, exist_ok=True)
    all_results = []

    with open(data_path, "r", encoding="utf-8") as f_in:
        async with MAS(oxy_space=oxy_space) as mas:
            task_idx = 0
            for line in f_in:
                task_idx += 1
                try:
                    task = json.loads(line.strip())
                    task_id = task.get("task_id", f"task_{task_idx}")
                    query = task.get("query", "")
                    file_name = task.get("file_name", "")

                    # å¤„ç†æ–‡ä»¶è·¯å¾„ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                    if file_name:
                        if file_name.startswith('[') and file_name.endswith(']'):
                            full_query = f"""
ä»»åŠ¡ä¿¡æ¯ï¼š
- æ–‡ä»¶åˆ—è¡¨ï¼š{file_name}
- é—®é¢˜ï¼š{query}
å›ç­”è§„åˆ™ï¼š
1. åŸºäºæ‰€æœ‰æ–‡ä»¶å†…å®¹ç»¼åˆåˆ†æå›ç­”ï¼›
2. ä¸¥æ ¼æŒ‰æ ¼å¼è¦æ±‚è¾“å‡ºï¼›
3. å¦‚æœæ— æ³•ä»æ–‡ä»¶ä¸­æ‰¾åˆ°ç¡®åˆ‡ç­”æ¡ˆï¼ŒåŸºäºç›¸å…³çŸ¥è¯†ç»™å‡ºåˆç†ç­”æ¡ˆï¼›
4. ç­”æ¡ˆä»…å«æ ¸å¿ƒä¿¡æ¯ï¼Œæ— å¤šä½™æ–‡å­—ï¼Œä¸åŒ…å«æ¢è¡Œç¬¦ï¼Œä»…å ä¸€è¡Œï¼›
5. ä¸è¦åŒ…å«"æ•°æ®æ¥æº"ç­‰è¯´æ˜æ€§æ–‡å­—ã€‚
"""
                        else:
                            full_file_path = str(Path(TEST_DIR_ABS) / file_name) if file_name else ""
                            full_query = f"""
ä»»åŠ¡ä¿¡æ¯ï¼š
- æ–‡ä»¶è·¯å¾„ï¼š{full_file_path}
- é—®é¢˜ï¼š{query}
å›ç­”è§„åˆ™ï¼š
1. ä¼˜å…ˆåŸºäºæ–‡ä»¶å†…å®¹å›ç­”ï¼›
2. ä¸¥æ ¼æŒ‰æ ¼å¼è¦æ±‚è¾“å‡ºï¼›
3. å¦‚æœæ— æ³•ä»æ–‡ä»¶ä¸­æ‰¾åˆ°ç¡®åˆ‡ç­”æ¡ˆï¼ŒåŸºäºç›¸å…³çŸ¥è¯†ç»™å‡ºåˆç†ç­”æ¡ˆï¼›
4. ç­”æ¡ˆä»…å«æ ¸å¿ƒä¿¡æ¯ï¼Œæ— å¤šä½™æ–‡å­—ï¼Œä¸åŒ…å«æ¢è¡Œç¬¦ï¼Œä»…å ä¸€è¡Œï¼›
5. ä¸è¦åŒ…å«"æ•°æ®æ¥æº"ç­‰è¯´æ˜æ€§æ–‡å­—ã€‚
"""
                    else:
                        full_query = f"""
ä»»åŠ¡ä¿¡æ¯ï¼š
- é—®é¢˜ï¼š{query}
å›ç­”è§„åˆ™ï¼š
1. ä¼˜å…ˆä½¿ç”¨ç™¾åº¦APIæœç´¢è·å–å®æ—¶æ•°æ®ï¼›
2. å¦‚æœæœç´¢å·¥å…·æ— æ³•è·å–ä¿¡æ¯ï¼ŒåŸºäºç›¸å…³çŸ¥è¯†ç»™å‡ºåˆç†ç­”æ¡ˆï¼›
3. ä¸¥æ ¼æŒ‰æ ¼å¼è¦æ±‚è¾“å‡ºï¼›
4. ç­”æ¡ˆä¸åŒ…å«æ¢è¡Œç¬¦ï¼Œä»…å ä¸€è¡Œï¼›
5. ä¸è¦åŒ…å«"æ•°æ®æ¥æº"ç­‰è¯´æ˜æ€§æ–‡å­—ã€‚
"""

                    payload = {
                        "query": full_query,
                        "callee": "master_agent"
                    }
                    oxy_response = await mas.chat_with_agent(payload=payload)
                    result = oxy_response.output
                    clean_result = result.strip()

                    # å¼ºåˆ¶æ ¼å¼ä¿®æ­£ - ç§»é™¤æ¢è¡Œç¬¦
                    clean_result = re.sub(r"\n|\r", "", clean_result)

                    # ğŸ”§ å¢å¼ºç‰ˆæ™ºèƒ½æå–æ ¸å¿ƒç­”æ¡ˆ
                    core_answer = extract_core_answer(clean_result, query)

                    # åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨æå–çš„ç­”æ¡ˆ
                    if should_use_extracted_answer(clean_result, core_answer, query):
                        clean_result = core_answer

                    # ç§»é™¤æ•°æ®æ¥æºç­‰è¯´æ˜æ€§æ–‡å­—
                    clean_result = re.sub(r'æ•°æ®æ¥æº[^ã€‚]*[ã€‚]?', '', clean_result)
                    clean_result = re.sub(r'æ¥æº[^ã€‚]*[ã€‚]?', '', clean_result)
                    clean_result = re.sub(r'åŸºäº[^ã€‚]*[ã€‚]?', '', clean_result)
                    clean_result = re.sub(r'æ ¹æ®[^ã€‚]*[ã€‚]?', '', clean_result)

                    # ç§»é™¤è¯·æ±‚æ–‡ä»¶è·¯å¾„çš„æç¤ºä¿¡æ¯ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                    path_request_patterns = [
                        r'è¯·æä¾›.*æ–‡ä»¶è·¯å¾„.*',
                        r'æˆ‘éœ€è¦æ‚¨æä¾›.*',
                        r'æ‚¨æä¾›çš„æ–‡ä»¶è·¯å¾„.*',
                        r'è¯·ç¡®è®¤.*æ–‡ä»¶è·¯å¾„.*',
                        r'è¯·é—®æ‚¨èƒ½æä¾›.*',
                        r'æ‚¨æåˆ°çš„æ–‡ä»¶è·¯å¾„.*',
                        r'è¯·æä¾›æ­£ç¡®çš„.*',
                        r'æˆ‘éœ€è¦æ‚¨æä¾›PDFæ–‡ä»¶çš„å®Œæ•´è·¯å¾„.*',
                        r'æ‚¨æä¾›çš„æ–‡ä»¶è·¯å¾„test.*',
                        r'è¯·æä¾›æ‚¨è¦åˆ†æçš„è§†é¢‘æ–‡ä»¶çš„å…·ä½“è·¯å¾„.*',
                        r'è¯·æä¾›è®¢å•ID.*',
                        r'è¯·æä¾›æ‚¨å¸Œæœ›æœç´¢çš„æ—¶é—´èŒƒå›´.*',
                        r'è¯·ç¡®è®¤é¡¹ç›®åç§°.*',
                        r'è¯·é—®æ‚¨å…·ä½“æŒ‡çš„æ˜¯å“ªä¸ª.*',
                        r'è¯·é—®æ‚¨çŸ¥é“.*å…·ä½“å‘å¸ƒæ—¥æœŸå—.*',
                        r'è¯·é—®æ‚¨èƒ½æä¾›.*æ³¨å†Œåœ°å€ä¿¡æ¯å—.*',
                        r'è¯·æä¾›å›¾ç‰‡æ–‡ä»¶.*'
                    ]

                    for pattern in path_request_patterns:
                        clean_result = re.sub(pattern, '', clean_result, flags=re.IGNORECASE)

                    # æ¸…ç†å¤šä½™çš„ç©ºæ ¼å’Œæ ‡ç‚¹
                    clean_result = re.sub(r'\s+', ' ', clean_result).strip()
                    clean_result = re.sub(r'^[ï¼Œã€‚ã€ï¼›]', '', clean_result)
                    clean_result = re.sub(r'[ï¼Œã€‚ã€ï¼›]$', '', clean_result)

                    # æ£€æŸ¥æ˜¯å¦æ˜¯é”™è¯¯æˆ–æœªæ‰¾åˆ°çš„ä¿¡æ¯
                    if (("not found" in clean_result.lower() or
                         "æ— æ³•è·å–" in clean_result or
                         "æœç´¢å¤±è´¥" in clean_result or
                         "error" in clean_result.lower() or
                         len(clean_result.strip()) == 0) and
                            len(clean_result) < 50):
                        clean_result = "Not found"
                    elif "not found in file" in clean_result.lower():
                        clean_result = "Not found"

                    # æå–æ ¼å¼è¦æ±‚å¹¶ä¼˜åŒ–è¾“å‡º
                    format_match = re.search(r"è¯·ç”¨(\w+.*?)(å›ç­”|è¾“å‡º)", query)
                    format_req = format_match.group(1).strip() if format_match else "plain text"

                    if "é˜¿æ‹‰ä¼¯æ•°å­—" in format_req:
                        num_match = re.search(r"\d+", clean_result)
                        if num_match:
                            clean_result = num_match.group()
                        else:
                            clean_result = "Not found"
                    elif "å°å†™è‹±æ–‡" in format_req:
                        clean_result = clean_result.lower()
                        color_match = re.search(
                            r"(red|blue|green|yellow|black|white|gray|grey|purple|orange|brown|pink|cyan|magenta)",
                            clean_result)
                        if color_match:
                            clean_result = color_match.group()
                        else:
                            clean_result = clean_result.lower()
                    elif "è‹±æ–‡å¤§å†™" in format_req or "å¤§å†™è‹±æ–‡" in format_req:
                        # ç¡®ä¿è‹±æ–‡å¤§å†™
                        clean_result = clean_result.upper()
                        # æå–æ ¸å¿ƒå¤§å†™å•è¯
                        uppercase_words = re.findall(r'\b[A-Z][A-Z]+\b', clean_result)
                        if uppercase_words:
                            clean_result = max(uppercase_words, key=len)
                    elif "æ–‡æœ¬" in format_req:
                        clean_result = re.sub(r"\s+", " ", clean_result)[:200]

                    # æœ€ç»ˆæ¸…ç†ï¼šç§»é™¤å¯èƒ½çš„é”™è¯¯æç¤ºä½†ä¿ç•™æœ‰ç”¨å†…å®¹
                    final_clean = re.sub(r'(ä»¥ä¸Šä¿¡æ¯ä»…ä¾›å‚è€ƒ|å»ºè®®.*?è·å–|æœç´¢.*?å¤±è´¥|æ— æ³•.*?è·å–)[^.]*\.?', '',
                                         clean_result)
                    if final_clean.strip():
                        clean_result = final_clean.strip()

                    # å¦‚æœæ¸…ç†åç»“æœä¸ºç©ºï¼Œè®¾ç½®ä¸ºNot found
                    if not clean_result.strip():
                        clean_result = "Not found"

                    all_results.append({
                        "task_id": task_id,
                        "answer": clean_result
                    })
                    print(
                        f"âœ… Processed task {task_idx} (ID: {task_id}) | Type: {file_name and 'File' or 'Common'} | Answer: {clean_result[:50]}...")

                except json.JSONDecodeError:
                    error_msg = "Error: Invalid JSON format"
                    all_results.append({
                        "task_id": f"invalid_task_{task_idx}",
                        "answer": error_msg
                    })
                    print(f"âŒ Task {task_idx} failed: Invalid JSON")
                except Exception as e:
                    error_str = str(e)[:100]
                    safe_error_str = re.sub(r'["\'\n\r\t\\]', ' ', error_str)
                    safe_error_str = re.sub(r'\s+', ' ', safe_error_str).strip()
                    error_msg = f"Error: {safe_error_str}" if safe_error_str else "Error: Unknown error"
                    all_results.append({
                        "task_id": f"error_task_{task_idx}",
                        "answer": error_msg
                    })
                    print(f"âŒ Task {task_idx} failed: {str(e)[:50]}...")

    # æŒ‰è¦æ±‚æ ¼å¼å†™å…¥æ–‡ä»¶
    with open(output_file, "w", encoding="utf-8") as f_out:
        f_out.write("[\n")
        for i, res in enumerate(all_results):
            f_out.write("  {\n")
            f_out.write(f'    "task_id": "{res["task_id"]}",\n')
            f_out.write(f'    "answer": "{res["answer"]}"\n')
            if i == len(all_results) - 1:
                f_out.write("  }\n")
            else:
                f_out.write("  },\n")
        f_out.write("]\n")

    print(f"\nğŸ‰ All tasks processed! Result saved to: {output_file}")


# -------------------------- ä¸»å‡½æ•° --------------------------
async def main():
    print("âš ï¸  Please confirm data desensitization is completed.")
    print("1. Run desensitization script (if needed):")
    print("   python desensitize_data.py --directory=./cache_dir/local_es_data/ --prefix=multi_format_qa_task_v1")
    print("2. Confirm desensitized files are in: ./cache_dir/local_es_data/local_es_data/ (if applicable)")
    input("\nPress Enter to continue...")

    await process_tasks(
        test_dir="test",
        output_file="result.jsonl"
    )


if __name__ == "__main__":
    asyncio.run(main())